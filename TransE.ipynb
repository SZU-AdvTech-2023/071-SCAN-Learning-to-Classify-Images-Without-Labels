{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4181f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02c8c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripleDataset(data.Dataset):\n",
    "    def __init__(self, ent2id, rel2id, triple_data_list):\n",
    "        self.ent2id = ent2id\n",
    "        self.rel2id = rel2id\n",
    "        self.data = triple_data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        head, relation, tail = self.data[index]\n",
    "        head_id = self.ent2id[head]\n",
    "        relation_id = self.rel2id[relation]\n",
    "        tail_id = self.ent2id[tail]\n",
    "        return head_id, relation_id, tail_id\n",
    "\n",
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, ent2id, rel2id, test_data_list):\n",
    "        self.ent2id = ent2id\n",
    "        self.rel2id = rel2id\n",
    "        self.data = test_data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        head, relation = self.data[index]\n",
    "        head_id = self.ent2id[head]\n",
    "        relation_id = self.rel2id[relation]\n",
    "        return head_id, relation_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8199bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(nn.Module):\n",
    "\n",
    "    def __init__(self, entity_num, relation_num, norm=1, dim=100):\n",
    "        super(TransE, self).__init__()\n",
    "        self.norm = norm\n",
    "        self.dim = dim\n",
    "        self.entity_num = entity_num\n",
    "        self.entities_emb = self._init_emb(entity_num)\n",
    "        self.relations_emb = self._init_emb(relation_num)\n",
    "\n",
    "    def _init_emb(self, num_embeddings):\n",
    "        embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=self.dim)\n",
    "        uniform_range = 6 / np.sqrt(self.dim)\n",
    "        embedding.weight.data.uniform_(-uniform_range, uniform_range)\n",
    "        embedding.weight.data = torch.div(embedding.weight.data, embedding.weight.data.norm(p=2, dim=1, keepdim=True))\n",
    "        return embedding\n",
    "\n",
    "    def forward(self, positive_triplets: torch.LongTensor, negative_triplets: torch.LongTensor):\n",
    "        positive_distances = self._distance(positive_triplets.cuda())\n",
    "        negative_distances = self._distance(negative_triplets.cuda())\n",
    "        return positive_distances, negative_distances\n",
    "\n",
    "    def _distance(self, triplets):\n",
    "        heads = self.entities_emb(triplets[:, 0])\n",
    "        relations = self.relations_emb(triplets[:, 1])\n",
    "        tails = self.entities_emb(triplets[:, 2])\n",
    "        return (heads + relations - tails).norm(p=self.norm, dim=1)\n",
    "\n",
    "    def link_predict(self, head, relation, tail=None, k=10):\n",
    "        h_add_r = self.entities_emb(head) + self.relations_emb(relation)\n",
    "        h_add_r = torch.unsqueeze(h_add_r, dim=1)\n",
    "        h_add_r = h_add_r.expand(h_add_r.shape[0], self.entity_num, self.dim)\n",
    "        embed_tail = self.entities_emb.weight.data.expand(h_add_r.shape[0], self.entity_num, self.dim)\n",
    "        values, indices = torch.topk(torch.norm(h_add_r - embed_tail, dim=2), k=self.entity_num, dim=1, largest=False)\n",
    "        if tail is not None:\n",
    "            tail = tail.view(-1, 1)\n",
    "            rank_num = torch.eq(indices, tail).nonzero().permute(1, 0)[1]+1\n",
    "            rank_num[rank_num > 9] = 10000\n",
    "            mrr = torch.sum(1/rank_num)\n",
    "            hits_1_num = torch.sum(torch.eq(indices[:, :1], tail)).item()\n",
    "            hits_3_num = torch.sum(torch.eq(indices[:, :3], tail)).item()\n",
    "            hits_10_num = torch.sum(torch.eq(indices[:, :10], tail)).item()\n",
    "            return mrr, hits_1_num, hits_3_num, hits_10_num\n",
    "        return indices[:, :k]\n",
    "\n",
    "    def evaluate(self, data_loader, dev_num=5000.0):\n",
    "        mrr_sum = hits_1_nums = hits_3_nums = hits_10_nums = 0\n",
    "        for heads, relations, tails in tqdm.tqdm(data_loader):\n",
    "            mrr_sum_batch, hits_1_num, hits_3_num, hits_10_num = self.link_predict(heads.cuda(), relations.cuda(), tails.cuda())\n",
    "            mrr_sum += mrr_sum_batch\n",
    "            hits_1_nums += hits_1_num\n",
    "            hits_3_nums += hits_3_num\n",
    "            hits_10_nums += hits_10_num\n",
    "        return mrr_sum/dev_num, hits_1_nums/dev_num, hits_3_nums/dev_num, hits_10_nums/dev_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d669974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 1500000\n",
    "dev_batch_size = 20 \n",
    "test_batch_size = 20\n",
    "epochs = 40\n",
    "margin = 1\n",
    "print_frequency = 5 \n",
    "validation = True \n",
    "dev_interval = 5  \n",
    "best_mrr = 0\n",
    "learning_rate = 0.001 \n",
    "distance_norm = 3  \n",
    "embedding_dim = 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6424ae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenBG500_entity2text.tsv', 'r', encoding='utf-8') as fp:\n",
    "    dat = fp.readlines()\n",
    "    lines = [line.strip('\\n').split('\\t') for line in dat]\n",
    "ent2id = {line[0]: i for i, line in enumerate(lines)}\n",
    "id2ent = {i: line[0] for i, line in enumerate(lines)}\n",
    "with open('OpenBG500_relation2text.tsv', 'r', encoding='utf-8') as fp:\n",
    "    dat = fp.readlines()\n",
    "    lines = [line.strip().split('\\t') for line in dat]\n",
    "rel2id = {line[0]: i for i, line in enumerate(lines)}\n",
    "with open('OpenBG500_train.tsv', 'r', encoding='utf-8') as fp:\n",
    "    dat = fp.readlines()\n",
    "    train = [line.strip('\\n').split('\\t') for line in dat]\n",
    "with open('OpenBG500_dev.tsv', 'r', encoding='utf-8') as fp:\n",
    "    dat = fp.readlines()\n",
    "    dev = [line.strip('\\n').split('\\t') for line in dat]\n",
    "with open('OpenBG500_test.tsv', 'r', encoding='utf-8') as fp:\n",
    "    test = fp.readlines()\n",
    "    test = [line.strip('\\n').split('\\t') for line in test]\n",
    "train_dataset = TripleDataset(ent2id, rel2id, train)\n",
    "dev_dataset = TripleDataset(ent2id, rel2id, dev)\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "dev_data_loader = data.DataLoader(dev_dataset, batch_size=dev_batch_size)\n",
    "test_dataset = TestDataset(ent2id, rel2id, test)\n",
    "test_data_loader = data.DataLoader(test_dataset, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9b6e7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "epoch:0/40, step:0/1, loss=0.19845178723335266, avg_loss=0.19845178723335266\n",
      "epoch:0/40, all_loss=0.19845178723335266\n",
      "epoch:1/40, step:0/1, loss=0.1952367126941681, avg_loss=0.1952367126941681\n",
      "epoch:1/40, all_loss=0.1952367126941681\n",
      "epoch:2/40, step:0/1, loss=0.19206662476062775, avg_loss=0.19206662476062775\n",
      "epoch:2/40, all_loss=0.19206662476062775\n",
      "epoch:3/40, step:0/1, loss=0.18893979489803314, avg_loss=0.18893979489803314\n",
      "epoch:3/40, all_loss=0.18893979489803314\n",
      "epoch:4/40, step:0/1, loss=0.18585456907749176, avg_loss=0.18585456907749176\n",
      "epoch:4/40, all_loss=0.18585456907749176\n",
      "testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:05<00:00, 49.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr: 0.5556533932685852, hit@1: 0.4526, hit@3: 0.6274, hit@10: 0.774  *\n",
      "epoch:5/40, step:0/1, loss=0.18281076848506927, avg_loss=0.18281076848506927\n",
      "epoch:5/40, all_loss=0.18281076848506927\n",
      "epoch:6/40, step:0/1, loss=0.17980754375457764, avg_loss=0.17980754375457764\n",
      "epoch:6/40, all_loss=0.17980754375457764\n",
      "epoch:7/40, step:0/1, loss=0.17684368789196014, avg_loss=0.17684368789196014\n",
      "epoch:7/40, all_loss=0.17684368789196014\n",
      "epoch:8/40, step:0/1, loss=0.17391838133335114, avg_loss=0.17391838133335114\n",
      "epoch:8/40, all_loss=0.17391838133335114\n",
      "epoch:9/40, step:0/1, loss=0.17103147506713867, avg_loss=0.17103147506713867\n",
      "epoch:9/40, all_loss=0.17103147506713867\n",
      "testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:05<00:00, 49.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr: 0.5562563538551331, hit@1: 0.453, hit@3: 0.629, hit@10: 0.7732  *\n",
      "epoch:10/40, step:0/1, loss=0.16818170249462128, avg_loss=0.16818170249462128\n",
      "epoch:10/40, all_loss=0.16818170249462128\n",
      "epoch:11/40, step:0/1, loss=0.16536882519721985, avg_loss=0.16536882519721985\n",
      "epoch:11/40, all_loss=0.16536882519721985\n",
      "epoch:12/40, step:0/1, loss=0.16259199380874634, avg_loss=0.16259199380874634\n",
      "epoch:12/40, all_loss=0.16259199380874634\n",
      "epoch:13/40, step:0/1, loss=0.1598510593175888, avg_loss=0.1598510593175888\n",
      "epoch:13/40, all_loss=0.1598510593175888\n",
      "epoch:14/40, step:0/1, loss=0.15714551508426666, avg_loss=0.15714551508426666\n",
      "epoch:14/40, all_loss=0.15714551508426666\n",
      "testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:05<00:00, 49.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr: 0.555634081363678, hit@1: 0.4514, hit@3: 0.629, hit@10: 0.774  \n",
      "epoch:15/40, step:0/1, loss=0.15447497367858887, avg_loss=0.15447497367858887\n",
      "epoch:15/40, all_loss=0.15447497367858887\n",
      "epoch:16/40, step:0/1, loss=0.1518394947052002, avg_loss=0.1518394947052002\n",
      "epoch:16/40, all_loss=0.1518394947052002\n",
      "epoch:17/40, step:0/1, loss=0.1492394357919693, avg_loss=0.1492394357919693\n",
      "epoch:17/40, all_loss=0.1492394357919693\n",
      "epoch:18/40, step:0/1, loss=0.14667434990406036, avg_loss=0.14667434990406036\n",
      "epoch:18/40, all_loss=0.14667434990406036\n",
      "epoch:19/40, step:0/1, loss=0.14414377510547638, avg_loss=0.14414377510547638\n",
      "epoch:19/40, all_loss=0.14414377510547638\n",
      "testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:05<00:00, 49.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr: 0.5557294487953186, hit@1: 0.4518, hit@3: 0.6276, hit@10: 0.7742  \n",
      "epoch:20/40, step:0/1, loss=0.14164771139621735, avg_loss=0.14164771139621735\n",
      "epoch:20/40, all_loss=0.14164771139621735\n",
      "epoch:21/40, step:0/1, loss=0.13918627798557281, avg_loss=0.13918627798557281\n",
      "epoch:21/40, all_loss=0.13918627798557281\n",
      "epoch:22/40, step:0/1, loss=0.13675960898399353, avg_loss=0.13675960898399353\n",
      "epoch:22/40, all_loss=0.13675960898399353\n",
      "epoch:23/40, step:0/1, loss=0.1343674510717392, avg_loss=0.1343674510717392\n",
      "epoch:23/40, all_loss=0.1343674510717392\n",
      "epoch:24/40, step:0/1, loss=0.13200916349887848, avg_loss=0.13200916349887848\n",
      "epoch:24/40, all_loss=0.13200916349887848\n",
      "testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:05<00:00, 49.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr: 0.5543740391731262, hit@1: 0.4498, hit@3: 0.628, hit@10: 0.7732  \n",
      "epoch:25/40, step:0/1, loss=0.12968449294567108, avg_loss=0.12968449294567108\n",
      "epoch:25/40, all_loss=0.12968449294567108\n",
      "epoch:26/40, step:0/1, loss=0.12739354372024536, avg_loss=0.12739354372024536\n",
      "epoch:26/40, all_loss=0.12739354372024536\n",
      "epoch:27/40, step:0/1, loss=0.12513600289821625, avg_loss=0.12513600289821625\n",
      "epoch:27/40, all_loss=0.12513600289821625\n",
      "epoch:28/40, step:0/1, loss=0.12291167676448822, avg_loss=0.12291167676448822\n",
      "epoch:28/40, all_loss=0.12291167676448822\n",
      "epoch:29/40, step:0/1, loss=0.12072039395570755, avg_loss=0.12072039395570755\n",
      "epoch:29/40, all_loss=0.12072039395570755\n",
      "testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:05<00:00, 49.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr: 0.553005039691925, hit@1: 0.4472, hit@3: 0.627, hit@10: 0.773  \n",
      "epoch:30/40, step:0/1, loss=0.11856217682361603, avg_loss=0.11856217682361603\n",
      "epoch:30/40, all_loss=0.11856217682361603\n",
      "epoch:31/40, step:0/1, loss=0.1164371594786644, avg_loss=0.1164371594786644\n",
      "epoch:31/40, all_loss=0.1164371594786644\n",
      "epoch:32/40, step:0/1, loss=0.11434491723775864, avg_loss=0.11434491723775864\n",
      "epoch:32/40, all_loss=0.11434491723775864\n",
      "epoch:33/40, step:0/1, loss=0.11228471249341965, avg_loss=0.11228471249341965\n",
      "epoch:33/40, all_loss=0.11228471249341965\n",
      "epoch:34/40, step:0/1, loss=0.11025642603635788, avg_loss=0.11025642603635788\n",
      "epoch:34/40, all_loss=0.11025642603635788\n",
      "testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:05<00:00, 49.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr: 0.5521336793899536, hit@1: 0.445, hit@3: 0.6282, hit@10: 0.773  \n",
      "epoch:35/40, step:0/1, loss=0.10825997591018677, avg_loss=0.10825997591018677\n",
      "epoch:35/40, all_loss=0.10825997591018677\n",
      "epoch:36/40, step:0/1, loss=0.10629507899284363, avg_loss=0.10629507899284363\n",
      "epoch:36/40, all_loss=0.10629507899284363\n",
      "epoch:37/40, step:0/1, loss=0.10436109453439713, avg_loss=0.10436109453439713\n",
      "epoch:37/40, all_loss=0.10436109453439713\n",
      "epoch:38/40, step:0/1, loss=0.10245858132839203, avg_loss=0.10245858132839203\n",
      "epoch:38/40, all_loss=0.10245858132839203\n",
      "epoch:39/40, step:0/1, loss=0.10058709979057312, avg_loss=0.10058709979057312\n",
      "epoch:39/40, all_loss=0.10058709979057312\n",
      "testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:05<00:00, 49.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mrr: 0.5508900880813599, hit@1: 0.4428, hit@3: 0.6292, hit@10: 0.774  \n"
     ]
    }
   ],
   "source": [
    "# model = TransE(len(ent2id), len(rel2id), norm=distance_norm, dim=embedding_dim).cuda()\n",
    "model.load_state_dict(torch.load('transE_best.pth'))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MarginRankingLoss(margin=margin, reduction='mean')\n",
    "print('start training...')\n",
    "for epoch in range(epochs):\n",
    "    all_loss = 0\n",
    "    for i, (local_heads, local_relations, local_tails) in enumerate(train_data_loader):\n",
    "\n",
    "        positive_triples = torch.stack((local_heads, local_relations, local_tails), dim=1).cuda()\n",
    "\n",
    "        # 生成负样本\n",
    "        head_or_tail = torch.randint(high=2, size=local_heads.size())\n",
    "        random_entities = torch.randint(high=len(ent2id), size=local_heads.size())\n",
    "        broken_heads = torch.where(head_or_tail == 1, random_entities, local_heads)\n",
    "        broken_tails = torch.where(head_or_tail == 0, random_entities, local_tails)\n",
    "        negative_triples = torch.stack((broken_heads, local_relations, broken_tails), dim=1).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pd, nd = model(positive_triples, negative_triples)\n",
    "        loss = criterion(pd, nd, torch.tensor([-1], dtype=torch.long).cuda())\n",
    "        loss.backward()\n",
    "        all_loss += loss.data\n",
    "        optimizer.step()\n",
    "        if i % print_frequency == 0:\n",
    "            print(\n",
    "                f\"epoch:{epoch}/{epochs}, step:{i}/{len(train_data_loader)}, loss={loss.item()}, avg_loss={all_loss / (i + 1)}\")\n",
    "    print(f\"epoch:{epoch}/{epochs}, all_loss={all_loss}\")\n",
    "\n",
    "    # 验证\n",
    "    if validation and (epoch + 1) % dev_interval == 0:\n",
    "        print('testing...')\n",
    "        improve = ''\n",
    "        mrr, hits1, hits3, hits10 = model.evaluate(dev_data_loader)\n",
    "        if mrr >= best_mrr:\n",
    "            best_mrr = mrr\n",
    "            improve = '*'\n",
    "            torch.save(model.state_dict(), 'transE_best.pth')\n",
    "        torch.save(model.state_dict(), 'transE_latest.pth')\n",
    "        print(f'mrr: {mrr}, hit@1: {hits1}, hit@3: {hits3}, hit@10: {hits10}  {improve}')\n",
    "    if not validation:\n",
    "        torch.save(model.state_dict(), 'transE_latest.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fe07525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:04<00:00, 50.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction finished !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict_all = []\n",
    "model.load_state_dict(torch.load('transE_best.pth'))\n",
    "for heads, relations in tqdm.tqdm(test_data_loader):\n",
    "    predict_id = model.link_predict(heads.cuda(), relations.cuda())\n",
    "    predict_list = predict_id.cpu().numpy().reshape(1,-1).squeeze(0).tolist()\n",
    "    predict_ent = map(lambda x: id2ent[x], predict_list)\n",
    "    predict_all.extend(predict_ent)\n",
    "print('prediction finished !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72da2ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved !\n"
     ]
    }
   ],
   "source": [
    "with open('submission.tsv', 'w', encoding='utf-8') as f:\n",
    "    for i in range(len(test)):\n",
    "        list = [x + '\\t' for x in test[i]] + [x + '\\n' if i == 9 else x + '\\t' for i, x in enumerate(predict_all[i*10:i*10+10])]\n",
    "        f.writelines(list)\n",
    "print('file saved !')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
